% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SFI.R
\name{SFI}
\alias{SFI}
\title{Sparse Family Index}
\usage{
SFI(G, y, h2 = 0.5, training = 1:length(y), testing = 1:length(y),
  indexG = NULL, subset = NULL, kernel = NULL, maxDF = NULL,
  lambda = NULL, nLambda = 100, method = c("CD1", "CD2", "LAR",
  "LAR-LASSO"), alpha = 1, name = NULL,
  nCores = getOption("mc.cores", 2L), tol = 2e-05, maxIter = 750,
  saveAt = NULL, verbose = TRUE)
}
\arguments{
\item{G}{Genetic relatedness matrix}

\item{y}{Response variable}

\item{h2}{Heritability of the response variable. Default is \eqn{h2=0.5}}

\item{training}{Index for the individuals in training set. Default is \eqn{training=1:length(y)} will consider all individuals as training}

\item{testing}{Index for the individuals in testing set. Default is \eqn{testing=1:length(y)} will consider all individuals as testing}

\item{subset}{A two-elements numeric vector \eqn{c(j,J)} to fit the model only for the 'jth' subset out of 'J' subsets that the
testing set will be divided into. Results can be automatically saved when 'saveAt' parameter is provided and can be retrieved later
using function 'collect'. Default is \eqn{subset=NULL} for no subsetting, then the model is fitted using all information}

\item{kernel}{Kernel transformation to be applied to 'G'. List consisting on one of:
\itemize{
  \item list(kernel='GAUSSIAN',h). If \eqn{h} is not provided the value of \eqn{h=-2*log(0.5)} is used.
  \item list(kernel='LAPLACIAN',h). If \eqn{h} is not provided the value of \eqn{h=-2*log(0.5)} is used.
  \item list(kernel='POLYNOMIAL',a,b). The values of \eqn{a=1} and \eqn{b=2} are used when they are not provided.
}
Default \eqn{kernel=NULL} (no kernel)}

\item{maxDF}{Maximum (average across individuals) number of predictors in the last solution (when method='LAR' or 'LAR-LASSO').
Default \eqn{maxDF=NULL} will calculate solutions including 1,2,...,nTRN predictors}

\item{lambda}{Penalization parameter sequence vector used for the Coordinate Descent algorithm.
Default is \eqn{lambda=NULL}, in this case a decreasing grid of
n='nLambda' lambdas will be generated starting from a maximum equal to \eqn{max(abs(G[training,testing])/alpha)} to a minumum equal to zero.
If \eqn{alpha=0} the grid is generated starting from a maximum equal to 5. Only needed for method='CD1' or 'CD2'}

\item{nLambda}{Number of lambdas generated when \eqn{lambda=NULL}}

\item{method}{One of:
\itemize{
 \item 'CD1': Coordinate Descent algorithm that computes the coefficients for a provided grid of lambdas common to all individuals in testing set.
 \item 'CD2': Similar to 'CD1' but using a grid of lambdas specific to each individual in testing set.
 \item 'LAR': Least Angle Regression algorithm that computes the entire sequence of all coefficients. Values of lambdas are calculated at each step.
 \item 'LAR-LASSO': Similar to 'LAR' but solutions when a predictor leaves the solution are also returned.
 \item 'GBLUP': Coefficients are derived with no penalization and they correspond to those of the genomic-BLUP
}}

\item{alpha}{Numeric between 0 and 1 indicating the weights for LASSO (alpha) and Ridge-Regression (1-alpha)}

\item{name}{Name given to the output for tagging purposes. Default \eqn{name=NULL} will give the name of the method used}

\item{nCores}{Number of cores used to run the analysis in parallel. Default is \eqn{nCores=2}}

\item{tol}{Maximum error between two consecutive solutions of the iterative algorithm to declare convergence}

\item{maxIter}{Maximum number of iterations to run at each lambda step before convergence is reached}

\item{saveAt}{Prefix name that will be added to the output files name to be saved, this may include a path. Regression coefficients
are saved as binary file as a single-precision (32 bits, 7 significant digits) variable. Default \eqn{saveAt=NULL} will no save any output}

\item{verbose}{TRUE or FALSE to whether printing each step}
}
\value{
List object containing the elements:
\itemize{
  \item BETA: list object containing, for each individual in testing set, a matrix of regression coefficients.
  \item alpha: value for the elastic-net weights used.
  \item lambda: matrix with the sequence of values of lambda used (for each individual in rows).
  \item df: degrees of freedom (averaged across individuals), number of non-zero predictors at each solution.
  \item kernel: transformation applied to the elements of 'G'.
}
Elements used as inputs: 'y','h2','training','testing','method','name', are also returned. The returned object is of the class 'SFI' for which methods 'fitted', 'predict', 'plot' and 'summary' exist
}
\description{
Computes the entire Elastic-Net solution for the regression coefficients of a Family Index simultaneously for all
values of the penalization parameter via either the Coordinate Descent (CD) or Least Angle Regression (LARS) algorithms.
}
\details{
The model is fitted for each individual which is predicted using all available observations \eqn{y=(y_1,...,y_n)} of the
response variable. The coefficients are estimated as function of the the 'variance' among predictors and the 'covariance'
between response and predictors which are taken from the genetic relatedness matrix (G).

The \eqn{n} coefficients \eqn{beta_i=(beta_i1,...,beta_in)} for the \eqn{i}th individual are obtained by optimizing the function
\deqn{-G[i,]' beta_i + 0.5 beta_i'(G + ((1-h^2)/h^2)I) beta_i + lambda J(beta_i)}
where \eqn{lambda} is the penalization parameter and \eqn{J(beta)} is a penalty function given by
\deqn{0.5(1-alpha)||beta_i||_2^2 + alpha||beta_i||_1}
The model can be fitted only for a subset of individuals in a testing set using a training set of individuals as predictors.
Each individual solution is found using the 'SSI' function (see help(SSI) or ?SSI)
}
\examples{
require(SFSI)
# Read data from BGLR package
data(wheat,package="BGLR")
X = scale(wheat.X)
G = tcrossprod(X)/ncol(X)    # Genomic relationship matrix
y = wheat.Y[,1]              # Response variable

# Training and testing sets
set.seed(1234)
n = length(y)
pTST = 0.3      # percentage to predict
tst = sample(1:n,floor(pTST*n))
trn = (1:n)[-tst]

# Calculate heritability
fm = BGLR::BGLR(y,ETA=list(list(K=G,model="RKHS")),nIter=10000,burnIn=3000,verbose=FALSE)
varU = fm$ETA[[1]]$varU
varE = fm$varE
h2 = varU/(varU + varE)

# Sparse family index
fm = SFI(G,y,h2,trn,tst)

yHat = fitted(fm)      # Predicted values or
pred = predict(fm)
yHat = pred$yHat       # Predicted values
corTST = cor(y[tst],yHat)[1,]  # Testing set accuracy
summary(fm)                    # Optimal accuracy
dat = data.frame(df=pred$df,logLambda=-log(pred$lambda),corTST)
plot(corTST ~ logLambda, data=dat[dat$df>1,]) # Accuracy along the regularization parameter
plot(fm)               # Same plot as above
plot(fm,py="MSE")      # MSE vs regularization
plot(fm,G=G)           # Coefficients path plot
plot(fm,G=G,PC=TRUE)   # Individual's training subsets
plot(fm,G=G,PC=TRUE,df=10)
}
\references{
\itemize{
\item \insertRef{Efron2004}{SFSI}
\item \insertRef{Friedman2007}{SFSI}
\item \insertRef{Hoerl1970}{SFSI}
\item \insertRef{Lush1947}{SFSI}
\item \insertRef{Perez2014}{SFSI}
\item \insertRef{Tibshirani1996}{SFSI}
\item \insertRef{VanRaden2008}{SFSI}
\item \insertRef{Zou2005}{SFSI}
}
}
\author{
Marco Lopez-Cruz (\email{lopezcru@msu.edu}) and Gustavo de los Campos
}
\keyword{SFI}
