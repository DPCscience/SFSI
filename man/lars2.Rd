% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lars.R
\name{lars2}
\alias{lars2}
\title{Least Angle Regression algorithm to solve the LASSO-type regression}
\usage{
lars2(XtX, Xty, method = c("LAR", "LAR-LASSO"), maxDF = NULL,
  eps = .Machine$double.eps, scale = TRUE, verbose = FALSE)
}
\arguments{
\item{XtX}{Variance-covariance matrix among predictors}

\item{Xty}{Covariance vector between response variable and predictors}

\item{method}{One of 'LAR' and 'LAR-LASSO'. Default is 'LAR'}

\item{maxDF}{Maximum number of predictors in the last lars solution.
Default \eqn{maxDF=NULL} will calculate solution for the total number of predictors given by \eqn{length(Xty)}}

\item{eps}{An effective zero. Default is the machine precision}

\item{scale}{TRUE or FALSE to whether scaling each entry of XtX and Xty
by the SD of the corresponding predictor taken from the diagonal of XtX}

\item{verbose}{TRUE or FALSE to whether printing each lars step}
}
\value{
List with the following elements:
\itemize{
  \item beta: vector of regression coefficients.
  \item lambda: penalty of LASSO-type problem for all the sequence of coefficients.
  \item df: degrees of freedom, number of non-zero predictors at each solution.
  \item sdx: vector of standard deviation of predictors.
}
}
\description{
Computes the entire LASSO solution for the regression coefficients, starting from zero, to the
least squares estimates, via the Least Angle Regression (LARS) algorithm (Efron, 2004). It uses as inputs
a 'variance' matrix among predictors and a 'covariance' vector between response and predictors
}
\examples{
set.seed(1234)
require(SFSI)
# Simulate variables
n = 500; p=200;  rho=0.65
X = matrix(rnorm(n*p),ncol=p)
eta = scale(X\%*\%rnorm(p))  # signal
e =  rnorm(n)              # error
y = rho*eta + sqrt(1-rho^2)*e

# Training and testing sets
pTST = 0.3      # percentage to predict
tst = sample(1:n,floor(pTST*n))
trn = (1:n)[-tst]

# Calculate covariances in training set
P = var(X[trn,])
rhs = as.vector(cov(y[trn],X[trn,]))

# Run the penalized regression
fm = lars2(P,rhs,method="LAR-LASSO",verbose=TRUE)

# Regression coefficients
beta = as.matrix(fm$beta)

# Predicted values in training and testing set
yHat_TRN =  X[trn,] \%*\% t(beta)
yHat_TST =  X[tst,] \%*\% t(beta)

par(mfrow=c(1,2))
plot(fm$df,cor(y[trn],yHat_TRN)[1,],main="Training set")
plot(fm$df,cor(y[tst],yHat_TST)[1,],main="Testing set")
}
\references{
\itemize{
\item \insertRef{Efron2004}{SFSI}
\item \insertRef{Hastie2013}{SFSI}
\item \insertRef{Tibshirani1996}{SFSI}
}
}
\author{
Marco Lopez-Cruz (\email{lopezcru@msu.edu}) and Gustavo de los Campos. Adapted from 'lars' package (Hastie & Efron, 2013)
}
\keyword{lars2}
