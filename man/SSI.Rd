% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SSI.R
\name{SSI}
\alias{SSI}
\title{Sparse Selection Index}
\usage{
SSI(XtX, Xty, kernel = NULL, scale = TRUE, maxDF = NULL,
  lambda = NULL, nLambda = 100, method = c("CD", "LAR", "LAR-LASSO"),
  alpha = 1, name = NULL, tol = 1e-05, maxIter = 1000,
  verbose = FALSE)
}
\arguments{
\item{XtX}{Variance-covariance matrix among predictors}

\item{Xty}{Covariance vector between response variable and predictors}

\item{kernel}{Kernel transformation to be applied to \code{XtX}. List consisting on one of:
\itemize{
  \item \code{list(kernel='GAUSSIAN',h)}. If \code{h} is not provided the value of \code{h=-2*log(0.5)} is used.
  \item \code{list(kernel='LAPLACIAN',h)}. If \code{h} is not provided the value of \code{h=-2*log(0.5)} is used.
  \item \code{list(kernel='POLYNOMIAL',a,b)}. The values of \code{a=1} and \code{b=2} are used when they are not provided.
}
Default \code{kernel=NULL} (no kernel)}

\item{scale}{\code{TRUE} or \code{FALSE} to recalculate the matrix \code{XtX} for variables with unit variance 
(see \code{help(scale_crossprod)}) and scale \code{Xty} by the standard deviation of the corresponding predictor
taken from the diagonal of \code{XtX}}

\item{maxDF}{Maximum (average across individuals) number of predictors in the last solution (when \code{method='LAR'} or \code{'LAR-LASSO'}).
Default \code{maxDF=NULL} will calculate solutions including 1,2,...,nTRN predictors}

\item{lambda}{Penalization parameter sequence vector used for the Coordinate Descent algorithm.
Default is \code{lambda=NULL}, in this case a decreasing grid of
\code{n='nLambda'} lambdas will be generated starting from a maximum equal to 
\tabular{c}{\code{max(abs(Xty)/alpha)}}
to a minimum equal to zero. If \code{alpha=0} the grid is generated starting from a maximum equal to 5}

\item{nLambda}{Number of lambdas generated when \code{lambda=NULL}}

\item{method}{One of:
\itemize{
 \item \code{'CD'}: Coordinate Descent algorithm that computes the coefficients for a provided grid of lambdas.
 \item \code{'LAR'}: Least Angle Regression algorithm that computes the entire sequence of all coefficients. Values of lambdas are calculated at each step.
 \item \code{'LAR-LASSO'}: Similar to \code{'LAR'} but solutions when a predictor leaves the solution are also returned.
}}

\item{alpha}{Numeric between 0 and 1 indicating the weights for LASSO (\eqn{\alpha=1}) and Ridge-Regression (\eqn{\alpha=0})}

\item{name}{Name given to the output for tagging purposes. Default \code{name=NULL} will give the name of the method used}

\item{tol}{Maximum error between two consecutive solutions of the iterative algorithm to declare convergence}

\item{maxIter}{Maximum number of iterations to run at each lambda step before convergence is reached}

\item{verbose}{\code{TRUE} or \code{FALSE} to whether printing each step}
}
\value{
List object containing the elements:
\itemize{
  \item \code{beta}: vector of regression coefficients.
  \item \code{alpha}: value for the elastic-net weights used.
  \item \code{lambda}: sequence of values of lambda used.
  \item \code{df}: degrees of freedom, number of non-zero predictors at each solution.
  \item \code{sdx}: vector of standard deviation of predictors.
  \item \code{kernel}: transformation applied to the elements of \code{XtX}.
}
The returned object is of the class 'SSI' for which methods \code{predict}, \code{plot} and \code{summary} exist
}
\description{
Computes the entire Elastic-Net solution for the regression coefficients of a penalized regression simultaneously for all
values of the penalization parameter via either the Coordinate Descent (Friedman, 2007) or Least Angle Regression (Efron, 2004) algorithms.
Analysis is performed using either 'solveEN' or 'lars2' functions.
}
\details{
The regression coefficients \eqn{\beta=(\beta_1,...,\beta_p)'} are estimated as function of the variance matrix among
predictors (\eqn{XtX}) and the covariance vector between response and predictors (\eqn{Xty}) by optimizing the function
\deqn{-Xty' \beta + 1/2\beta' (XtX)\beta + \lambda J(\beta)}
where \eqn{\lambda} is the penalization parameter and \eqn{J(\beta)} is a penalty function given by
\deqn{1/2(1-\alpha)||\beta||_2^2 + \alpha||\beta||_1}
for \eqn{\alpha} between 0 and 1
}
\examples{
set.seed(1234)
require(SFSI)
# Simulate variables
n=500; p=200;  rho=0.65
X = matrix(rnorm(n*p),ncol=p)
signal = rho*scale(X\%*\%rnorm(p))
noise =  sqrt(1-rho^2)*rnorm(n)
y = signal + noise

# Training and testing sets
pTST = 0.3      # percentage to predict
tst = sample(1:n,floor(pTST*n))
trn = (1:n)[-tst]

# Calculate covariances in training set
P = var(X[trn,])
rhs = as.vector(cov(y[trn],X[trn,]))

# Run the penalized regression
fm = SSI(P,rhs)                    # or
fm = SSI(P,rhs,method="LAR")       # or
fm = SSI(P,rhs,method="LAR-LASSO")

# Regression coefficients
plot(fm)  # Path plot along lambda
beta = as.matrix(fm$beta)

# Predicted values in training and testing set
yHat_TRN =  X[trn,] \%*\% t(beta)   # or
yHat_TRN =  predict(fm,X[trn,])

yHat_TST =  X[tst,] \%*\% t(beta)   # or
yHat_TST =  predict(fm,X[tst,])

par(mfrow=c(1,2))
plot(fm$df,cor(y[trn],yHat_TRN)[1,],main="Training set")
plot(fm$df,cor(y[tst],yHat_TST)[1,],main="Testing set")
}
\references{
\itemize{
\item \insertRef{Efron2004}{SFSI}
\item \insertRef{Friedman2007}{SFSI}
\item \insertRef{Hoerl1970}{SFSI}
\item \insertRef{Tibshirani1996}{SFSI}
\item \insertRef{VanRaden2008}{SFSI}
\item \insertRef{Zou2005}{SFSI}
}
}
\author{
Marco Lopez-Cruz (\email{lopezcru@msu.edu}) and Gustavo de los Campos
}
\keyword{SSI}
